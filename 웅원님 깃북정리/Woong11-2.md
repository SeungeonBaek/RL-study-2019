ì¶œì²˜ : https://dnddnjs.gitbooks.io/rl/content
/*ì´ì›…ì›ë‹˜ Git*/

# Policy Gradient

## Monte-Carlo Policy Gradient : REINFORCE

  ì•ì—ì„œ ì‚´í´ë´¤ë˜ Finite difference policy gradientëŠ” numericalí•œ ë°©ë²•ì´ê³  ì•ìœ¼ë¡œ ì‚´í´ë³¼ Monte-Carlo Policy Gradientì™€ Actor-Criticì€ analyticí•˜ê²Œ gradientë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. analyticí•˜ê²Œ gradientë¥¼ ê³„ì‚°í•œë‹¤ëŠ” ê²ƒì€ objective functionì— ì§ì ‘ gradientë¥¼ ì·¨í•´ì¤€ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë•Œ, policyëŠ” ë¯¸ë¶„ ê°€ëŠ¥í•˜ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.

  ì´ ë•Œ gradientë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì„ episodeë§ˆë‹¤ í•´ì£¼ë©´ MC Policy Gradientì´ê³  time-stepë§ˆë‹¤ ê³„ì‚°í•  ìˆ˜ ìˆìœ¼ë©´ Actor-criticì…ë‹ˆë‹¤. ë°‘ì—ì„œ ë³´ë©´ score functionì´ë¼ëŠ” ê²ƒì´ ë‚˜ì˜µë‹ˆë‹¤. score functionì´ë€ ë¬´ì—‡ì¼ê¹Œìš”?

## 1. Score function

  analyticí•˜ê²Œ gradientë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œ Objective functionì— ì§ì ‘ gradientë¥¼ ì·¨í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‹ì„ ì–»ìŠµë‹ˆë‹¤. objective functionìœ¼ë¡œ average reward formulationì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

  Gradientë¥¼ ğœƒì— ëŒ€í•´ì„œ ì·¨í•˜ê¸° ë•Œë¬¸ì— objective functionì˜ ì‹ ì¤‘ì—ì„œ policyì—ë§Œ gradientë¥¼ ì·¨í•˜ë©´ ë˜ì„œ ì•ˆìª½ìœ¼ë¡œ ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤.

    J(ğœƒ) = E_ğœ‹ğœƒ[r] = {s âˆˆ S} Î£ d(s) {a âˆˆ A} Î£ ğœ‹_(s,a) * R^s_a

    
