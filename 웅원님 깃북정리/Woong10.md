ì¶œì²˜ : https://dnddnjs.gitbooks.io/rl/content
/*ì´ì›…ì›ë‹˜ Git*/ DQN

# Neural Network

## 1. What is DQN

  ê°•í™”í•™ìŠµì—ì„œ agentëŠ” environmentë¥¼ MDPë¥¼ í†µí•´ì„œ ì´í•´ë¥¼ í•˜ëŠ”ë° tableí˜•íƒœë¡œ í•™ìŠµì„ ëª¨ë“  stateì— ëŒ€í•œ action-value functionì˜ ê°’ì„ ì €ì¥í•˜ê³  update ì‹œì¼œë‚˜ê°€ëŠ” ì‹ìœ¼ë¡œ í•˜ë©´ í•™ìŠµì´ ìƒë‹¹íˆ ëŠë ¤ì§‘ë‹ˆë‹¤. ë”°ë¼ì„œ approximationì„ í•˜ê²Œ ë˜ê³ , ê·¸ approximationë°© ì¤‘ì—ì„œ nonlinear function approximatorë¡œ deep neural networkê°€ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ action-value function(q-value)ë¥¼ approximateí•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ã…‡eep neural networkë¥¼ íƒí•œ reinforcement learningë°©ë²•ì´ Deep Rienforcement Learning(deepRL)ì…ë‹ˆë‹¤. ë˜í•œ action value functionë¿ë§Œ ì•„ë‹ˆë¼ policy ìì²´ë¥¼ approximateí•  ìˆ˜ë„ ìˆëŠ”ë° ê·¸ approximatorë¡œ DNNì„ ì‚¬ìš©í•´ë„ DeepRLì´ ë©ë‹ˆë‹¤.

  action value functionì„ approximateí•˜ëŠ” deep neural networksë¥¼ Deep Q-Networks(DQN)ì´ë¼ê³  í•˜ëŠ”ë° ê·¸ë ‡ë‹¤ë©´ DQNìœ¼ë¡œ ì–´ë–»ê²Œ í•›ë¸Œí• ê¹Œìš”? DQNì´ë¼ëŠ” ê°œë…ì€ DeepMindì˜ "Playing Atari with Deep Reinforcement Learning"ì´ë¼ëŠ” ë…¼ë¬¸ì— ì†Œê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
  https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf

***

## 2. Artificial Neural Networks (ANN)

  http://sanghyukchun.github.io/74/
  http://arxiv.org/pdf/cs/0308031.pdf
  http://www.slideshare.net/imanog/artificial-neural-network-48027460
  http://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks
  ì´ì›…ì› ë‹˜ì€ ë‹¤ìŒì˜ referenceë¥¼ í†µí•´ì„œ ê¹ƒë¶ì„ ì‘ì„±í–ˆë‹¤ê³  í•©ë‹ˆë‹¤.

  DeepRLì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ë”¥ëŸ¬ë‹ì˜ ê¸°ë³¸ì ì¸ ê°œë…ì— ëŒ€í•´ì„œ ì•Œ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ê°•í™”í•™ìŠµì´ ì‚¬ëŒì˜ í–‰ë™ë°©ì‹ì„ ëª¨ë°©í–ˆë‹¤ë¼ê³  í•œë‹¤ë©´, artificial neural networksëŠ” ì‚¬ëŒì˜ ë‡Œì˜ êµ¬ì¡°ë¥¼ ëª¨ë°©í–ˆìŠµë‹ˆë‹¤.

  ì¸ê³µì§€ëŠ¥ì´ ì‚¬ëŒì˜ ë‡Œë¥¼ ëª¨ë°©í•˜ê²Œ ëœ ê²ƒì—ëŠ” ì»´í“¨í„°ê°€ ê³„ì‚°ê³¼ ê°™ì€ ì¼ì—ëŠ” ì‚¬ëŒë³´ë‹¤ ë›°ì–´ë‚œ performanceë¥¼ ë‚´ì§€ë§Œ ê°œì™€ ê³ ì–‘ì´ë¥¼ êµ¬ë³„í•˜ëŠ” ì‚¬ëŒì´ë¼ë©´ ëˆ„êµ¬ë‚˜ ê°„ë‹¨í•˜ê²Œ í•˜ëŠ” ì¼ì€ ì»´í“¨í„°ëŠ” í•˜ì§€ ëª»í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

  ë”°ë¼ì„œ ì´ë¯¸ ë‡Œì˜ êµ¬ì¡°ì— ëŒ€í•´ì„œëŠ” ìˆ˜ë§ìœ¼ ë‰´ëŸ°ë“¤ê³¼ ì‹œëƒ…ìŠ¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œê³  ê·¸ê²ƒì„ ìˆ˜í•™ì  ëª¨ë¸ë¡œ ë§Œë“¤ì–´ì„œ ì»´í“¨í„°ì˜ ì•Œê³ ë¦¬ì¦˜ì— ì ìš©ì‹œí‚¤ëŠ” ë°©ë²•ì„ íƒí•œ ê²ƒì…ë‹ˆë‹¤.

  neural networksì˜ ìˆ˜í•™ì  ëª¨ë¸ì€ ì‹¤ì œ ë‰´ëŸ°ì˜ êµ¬ì¡° ë° í™”í•™ì  ì›ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ ì¡ŒìŠµë‹ˆë‹¤. ê° Neuronë“¤ì€ synapseë¥¼ í†µí•´ì„œ signalì„ ë°›ìŠµë‹ˆë‹¤. ë§Œì•½ signalì´ ì–´ë–¤ íŠ¹ì •í•œ thresholdë¥¼ ë„˜ì–´ê°„ë‹¤ë©´ neruonì´ activateë˜ê³  ê·¸ ë‰´ëŸ°ì€ axonì„ í†µí•´ì„œ signalì„ ë‹¤ë¥¸ synapseë¡œ ë³´ëƒ…ë‹ˆë‹¤.

  ë˜í•œ ë³´í†µ ë‰´ëŸ°ì€ ì—¬ëŸ¬ê°œì˜ inputì´ ë“¤ì–´ì™€ì„œ ì—¬ëŸ¬ê°œì˜ outputì´ ë‚˜ê°€ëŠ” êµ¬ì¡°ì´ë©°, ê·¸ inputê³¼ outputì€ ë‰´ëŸ°ì‚¬ì´ì˜ ì—°ê²°ì„ í†µí•´ì„œ ì „ë‹¬ì´ ë©ë‹ˆë‹¤.

  ì˜ˆë¥¼ ë“¤ì–´ ë‰´ëŸ°ì˜ ì‹œëƒ…ìŠ¤ê°€ 10ê°œë¼ê³  ê°€ì •í•˜ê²Œ ë˜ë©´ ì´ ì‹œëƒ…ìŠ¤ë¥¼ í†µí•´ì„œ 10ê°œì˜ ë‹¤ë¥¸ inputë“¤ì´ ë“¤ì–´ì˜¤ê²Œ ë©ë‹ˆë‹¤. ë˜í•œ neuronì˜ processì— ë“¤ì–´ê°€ëŠ” ê°’ì€ ì´ 10ê°œì˜ inputë“¤ì˜ linear combinationì…ë‹ˆë‹¤. ì´ processë¥¼ ê±°ì¹œ yê°’ì€ ë‹¤ì‹œ ë‹¤ë¥¸ ë‰´ëŸ°ë“¤ì˜ synapseì˜ inputìœ¼ë¡œ ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‚¬ëŒì˜ ë‰´ëŸ°ì˜ êµ¬ì¡°ë¥¼ ëª¨ë°©í•´ì„œ ì¸ê³µì‹ ê²½ë§ì„ êµ¬ì„±í•˜ê²Œ ë˜ë©´, ê° neuronì€ nodeê°€ ë˜ê³  synapseë¥¼ í†µí•´ì„œ ë“¤ì–´ì˜¤ëŠ” signalì€ inputì´ ë˜ê³  ê°ê° ë‹¤ë¥¸ synapseë¥¼ í†µí•´ì„œ ë“¤ì–´ì˜¤ëŠ” signalë“¤ì˜ ì¤‘ìš”ë„ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ weightë¥¼ ê³±í•´ì¤˜ì„œ ë“¤ì–´ì˜¤ê²Œ ë©ë‹ˆë‹¤.

  ì´ signalë“¤ì´ wiehgtì™€ ê³±í•´ì§„ ê²ƒì´ ë°”ë¡œ net input signal(ì•Œì§œ ì…ë ¥ ì‹ í˜¸)ì…ë‹ˆë‹¤. ê·¸ net input signalì„ ì‹ìœ¼ë¡œ í‘œí˜„í•˜ê²Œ ë˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

    > Net input signal received through synaptic junctions is
      net = b + Î£ w_i * x_i = b + W^T * x

      Wieght vector : W = [w_1, w_2, ... , w_m]'

      Input vector  : X = [x_1, x_2, ... , x_m]'

      Each output is a function of the net stimulus signal(f is called the activation function)

        y = f(net) = f(b + W^T * x)

  ì‹œëƒ…ìŠ¤ë¡œ ë“¤ì–´ì˜¤ëŠ” ê°ê°ì˜ inputì„ vectorë¡œ í‘œí˜„í•˜ê³  ê·¸ inputì— ê°ê° ê³±í•´ì§€ëŠ” weight ë˜í•œ ê·¸ì— ë”°ë¼ vectorë¡œ ë§Œë“¤ì–´ì„œ ë‘ vectorë¥¼ ê³±í•´ì„œ inputê³¼ weightì˜ linear combinationì„ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. ì—¬ê¸°ì„œ ìƒˆë¡œìš´ ê°œë…ì´ ë‚˜íƒ€ë‚˜ëŠ”ë°, bë¡œ ì¨ì§€ëŠ” biasì…ë‹ˆë‹¤.

  Biasê°€ linear combinationì— ë”í•´ì ¸ì„œ net input signalë¡œ ë“¤ì–´ê°€ëŠ” ì´ìœ ëŠ” ê°„ë‹¨í•˜ê²Œ ë§í•˜ìë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì¢Œí‘œí‰ë©´ì—ì„œ (0,0)ê³¼ (5,5)ë¥¼ ì–´ë– í•œ ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„í•˜ê³  ì‹¶ë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤.

  biasê°€ ì—†ëŠ” y = axê°™ì€ í•¨ìˆ˜ì˜ ê²½ìš°ì—ëŠ” ë‘ ì ì„ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ì „í˜€ ì—†ìŠµë‹ˆë‹¤. (0,0)ì´ ì§ì„  ìœ„ì— ìˆê¸° ë•Œë¬¸ì´ì£ . í•˜ì§€ë§Œ, y = ax + bì˜ í•¨ìˆ˜ëŠ” ì´ ë‘ì ì„ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  ë˜í•œ ë‹¤ë¥¸ ì‹ìœ¼ë¡œ biasì˜ í•„ìš”ì„±ì„ ì„¤ëª…í•œ stackoverflowì˜ ëŒ“ê¸€ì´ ìˆìŠµë‹ˆë‹¤.

    > Role of bias in neural networks
      Modification of neuron WEIGHTS alone only serves to manipulate the shape/curvature of your transfer function, and not its equilibrium/zero crossing points.
      The introduction of BIAS neurons allows you to shift the transfer function curve horizontally (left/right) along the input axis while leaving the shape/curvature unaltered.
      This will allow the network to produce arbitrary outputs differnet from the defaults and hence you can customize/shift the input to output mapping to suit your particular needs.

  ì¦‰, ë…¸ë“œë¡œ ë“¤ì–´ê°€ëŠ” inputë“¤ì— ê³±í•´ì§€ëŠ” weight(í•™ìŠµì‹œí‚¤ë ¤ëŠ” ëŒ€ìƒ)ì„ ë³€í™”ì‹œí‚¤ë©´ í•¨ìˆ˜ì˜ ëª¨ì–‘ë§Œ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆì§€, ì™¼ìª½/ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™ì‹œì¼œì„œ 0ì´ ë˜ëŠ” pointë¥¼ ë³€í˜• ì‹œí‚¬ìˆ˜ëŠ” ì—†ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

  ë”°ë¼ì„œ biasë¥¼ ì‚¬ìš©í•˜ë©´ ìš”êµ¬ì— ë”°ë¼ ê·¸ë˜í”„ë¥¼ ì´ë™ ë° ë³€í˜•ì‹œì¼œì„œ í•™ìŠµí•  ìˆ˜ê°€ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

  Input signalë“¤ê³¼ weightì´ ê³±í•´ì§€ê³  biasê°€ ë”í•´ì§„ net input signalì´ nodeë¥¼ activateì‹œí‚¤ëŠ”ë° ê·¸ í˜•ì‹ì„ functionìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬í•œ í•¨ìˆ˜ë¥¼ activation functionì´ë¼ í•©ë‹ˆë‹¤.

  ìœ„ ìœ„ì˜ ì‹ì—ì„œ fë¡œ í‘œí˜„í•œ activation functionì˜ ê°€ì¥ ê°„ë‹¨í•œ í˜•íƒœëŠ” ë“¤ì–´ì˜¨ inputë“¤ì˜ í•©ì´ ì–´ë–¤ thresholdë³´ë‹¤ ë†’ìœ¼ë©´ 1ì´ ë‚˜ì˜¤ê³  ë‚®ìœ¼ë©´ 0ì´ ë‚˜ì˜¤ëŠ” í˜•íƒœì¼ ê²ƒì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ëŸ° í˜•íƒœì˜ activation functionì˜ ê²½ìš°ì—ëŠ” ë¯¸ë¶„ì´ ë¶ˆê°€ëŠ¥ í•˜ë‹¤ëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ´ ê²½ìš° gradient descentë¥¼ í†µí•œ ìµœì í™”ë¥¼ ì§„í–‰í•˜ì§€ ëª» í•˜ê¸° ë•Œë¬¸ì—, ê·¸ ì´ì™¸ì˜ ë¯¸ë¶„ê°€ëŠ¥í•œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

  ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ê°„ë‹¨í•œ activation functionì€ sigmoid functionì…ë‹ˆë‹¤. sigmoid functionì´ë€ ë¬´ì—‡ì¼ê¹Œìš”? f(x) = 1 / (1 + e^-ax)ë¡œ í‘œí˜„ë˜ë©°, [0 1]ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

  activation functionì˜ ì˜ˆì‹œì—ëŠ” sigmoid ë§ê³ ë„ ì„¸ ê°€ì§€ ë‹¤ë¥¸ í•¨ìˆ˜ë“¤ì´ ìˆëŠ”ë° ì´ í•¨ìˆ˜ë“¤ì€ ëª¨ë‘ non-linearí•©ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” activation functionì´ linearí•  ê²½ìš°ì—ëŠ” ì•„ë¬´ë¦¬ ë§ì€ neuron layerë¥¼ ìŒ“ëŠ”ë‹¤ í•˜ë”ë¼ë„ ê·¸ê²ƒì´ ê²°êµ­ í•˜ë‚˜ì˜ layerë¡œ í‘œí˜„ì´ ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

  - sigmoid function
  - tanh function
  - absolute function
  - ReLU function

  ê°€ì¥ ì‹¤ìš©ì ì¸ activation functionì€ ReLU functionì´ë¼ê³ ë“¤ í•©ë‹ˆë‹¤. ReLUë€ ì–´ë–¤ í•¨ìˆ˜ì¼ê¹Œìš”?

  ReLU í•¨ìˆ˜ëŠ” xê°€ 0ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì„ë•ŒëŠ” yê°€ 0ì´ ë‚˜ì˜¤ê³ , xê°€ 0ë³´ë‹¤ í´ ê²½ìš°ì—ëŠ” y = xì˜ í˜•íƒœë¥¼ ë„ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

  ì‚¬ì‹¤ ë”¥ëŸ¬ë‹ì´ ìµœê·¼ì— ê°‘ìê¸° ê¸‰ ë¶€ìƒí•œ ì´ìœ ì—ëŠ” ì—„ì²­ë‚˜ê²Œ í˜ì‹ ì ì¸ ë³€í™”ê°€ ìˆì—ˆë‹¤ê¸° ë³´ë‹¤ëŠ” Computation timeì˜ ê°ì†Œì™€ ë”ë¶ˆì–´ activation functionì„ sigmoidì—ì„œ ReLUë¡œ ë°”ê¾¸ëŠ” ë“±ì˜ ì‘ì€ ë³€í™”ë“¤ì´ ì¤‘ì²©ë˜ë©° ì¼ì–´ë‚¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

  sigmoid í•¨ìˆ˜ì— ë¹„í•´ ReLUê°€ ê°€ì§€ê³  ìˆëŠ” ì¥ì ì€ ì–´ë–¤ ê²ƒì´ ìˆëŠ”ì§€ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ReLUì˜ ì§ì„ ì ì´ í˜•íƒœì™€ sigmoidí•¨ìˆ˜ ì²˜ëŸ¼ ìˆ˜ë ´í•˜ëŠ” í˜•íƒœê°€ ì•„ë‹Œ ì ì´ ReLUì˜ stochastic gradient descentê°€ ë” ì˜ ìˆ˜ë ´í•˜ê²Œ í•´ì¤ë‹ˆë‹¤. ë˜í•œ ìƒëŒ€ì ìœ¼ë¡œ sigmoidí•¨ìˆ˜ì— ë¹„í•´ì„œ ê³„ì‚°ëŸ‰ì´ ì¤„ì–´ë“ ë‹¤ëŠ” ì¥ì ë„ ìˆìŠµë‹ˆë‹¤.

  ì¥ì ì´ ìˆìœ¼ë©´ ë‹¨ì ë„ ìˆëŠ” ë²•ì…ë‹ˆë‹¤. ë‹¨ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. Learning rateì— ë”°ë¼ì„œ ì¤‘ê°„ì— ìµœëŒ€ 40%ì˜ networkê°€ "die"í•  ìˆ˜ ìˆë‹¤ê³  í•©ë‹ˆë‹¤. ë‹¨, learning rateë¥¼ ì˜ ì¡°ì ˆí•˜ë©´ ì´ ë¬¸ì œëŠ” ê·¸ë ‡ê²Œ í¬ì§€ ì•Šë‹¤ê³  í•©ë‹ˆë‹¤.

***

## 3. Stochastic Gradient Descent(SGD) and Back-Propagation

### (1) SGD

  ì§€ê¸ˆê¹Œì§€ëŠ” deep neural networkê°€ ë¬´ì—‡ì¸ì§€ì— ëŒ€í•´ì„œ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì´ê¸€ì˜ ì²­ë¯€ìœ¼ë¡œ ëŒì•„ê°€ì„œ DQNì´ë€ action-value functionì„ deep neural networkë¡œ approximation í•œ ê²ƒì„ ë§í•©ë‹ˆë‹¤. ê°•í™”í•™ìŠµì˜ ëª©í‘œëŠ” optimal policyë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ê³  ê° stateì—ì„œ optimalí•œ action value fucntionì„ ì•Œê³  ìˆìœ¼ë©´ q ê°’ì´ í° actionì„ ì·¨í•˜ë©´ ë˜ëŠ” ê²ƒì´ë¯€ë¡œ ê²°êµ­ì€ q-valueë¥¼ êµ¬í•˜ë©´ ê°•í™”í•™ìŠµ ë¬¸ì œë¥¼ í’€ê²Œ ë©ë‹ˆë‹¤.

  ì´ q-valueëŠ” DNN(deep neural networks)ë¥¼ í†µí•´ì„œ ë‚˜ì˜¤ê²Œ ë˜ëŠ”ë° ê²°êµ­ DNNì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ëª©í‘œê°€ ë˜ê²Œ ë©ë‹ˆë‹¤.

  ë”°ë¼ì„œ approximationí•˜ì§€ ì•Šì•˜ì„ ë•Œì™€ ë‹¤ë¥¸ ê²ƒì€ q-tableì„ ë§Œë“¤ì–´ì„œ ê°ê°ì˜ q-valueë¥¼ updateí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆê³  DNNì•ˆì˜ weightì™€ biasë¥¼ updateí•˜ê²Œ ë©ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì–´ë–»ê²Œ updateí• ê¹Œìš”?

  ì´ ë•Œ ì´ì „ì— ë°°ì› ë–¤ Stochastic Gradient Descentê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. ì •ë¦¬í•˜ìë©´ graidnet descentë¼ëŠ” ê²ƒì€ wë¥¼ parameterë¡œ ê°€ì§€ëŠ” Jë¼ëŠ” objective funcitonì„ minimize í•˜ëŠ” ë°©ë²•ì¤‘ì˜ í•˜ë‚˜ë¡œì¨ wì— ëŒ€í•œ Jì˜ gradient ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ wë¥¼ updateí•˜ëŠ” ë°©ì‹ì„ ë§í•©ë‹ˆë‹¤.

    > Gradient descent
        âˆ†w = -(1/2) * ğ›¼ * âˆ‡w J(w)
           = ğ›¼ * E_ğœ‹[{v_ğœ‹(s)-vhat(s,w)} * âˆ‡w vhat(s,w)]

      Stochastic Gradient descent samples the gradient
        âˆ†w = ğ›¼ * {v_ğœ‹(s)-vhat(s,w)} * âˆ‡w vhat(s,w)

  ì´ëŸ° ì‹ìœ¼ë¡œ updateë¥¼ í•˜ê²Œ ë˜ëŠ”ë° ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ì„œ gardientë¥¼ êµ¬í•´ì„œ í•œ ë²ˆ updatí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆê³  Samplingì„ í†µí•´ì„œ ìˆœì°¨ì ìœ¼ë¡œ updateë¥¼ í•˜ê² ë‹¤ëŠ” gradient descent ë°©ë²•ì´ stochastic gradient descentì…ë‹ˆë‹¤.

  ì•„ë˜ í˜ì´ì§€ë¥¼ ì°¸ê³ í•´ë³´ë©´ ê·¸ë ‡ê²Œ í•  ê²½ìš° ìˆ˜ë ´í•˜ëŠ” ì†ë„ê°€ í›¨ì”¬ ë¹ ë¥´ë©° onlineìœ¼ë¡œë„ í•™ìŠµí•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ í•˜ë‚˜ ì¤‘ìš”í•œ ì ì€ gradient descentë°©ë²•ì´ local optimumìœ¼ë¡œ ê°ˆ ìˆ˜ ìˆë‹¤ëŠ” ë‹¨ì ì´ ìˆëŠ” ìµœì í™” ë°©ë²•ì´ë¼ëŠ” ê²ƒì„ ê¸°ì–µ í•´ì•¼ í•©ë‹ˆë‹¤.

### (1) Back-Propagation


















asdf
